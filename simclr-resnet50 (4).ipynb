{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":3907076,"sourceType":"datasetVersion","datasetId":2308447}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        os.path.join(dirname, filename)\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-17T05:00:10.901855Z","iopub.execute_input":"2025-08-17T05:00:10.902041Z","iopub.status.idle":"2025-08-17T05:00:27.534756Z","shell.execute_reply.started":"2025-08-17T05:00:10.902025Z","shell.execute_reply":"2025-08-17T05:00:27.534008Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Library","metadata":{}},{"cell_type":"code","source":"import os, random, time, math, sys\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom PIL import Image\nfrom tqdm import tqdm\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader, Subset, random_split\nfrom torchvision import transforms as T\nfrom torchvision.datasets import ImageFolder\nimport torchvision.models as models\n\nfrom sklearn.metrics import classification_report, roc_curve, roc_auc_score\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nfrom sklearn.preprocessing import label_binarize\nfrom sklearn.manifold import TSNE\nimport umap.umap_ as umap\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-17T05:00:27.535598Z","iopub.execute_input":"2025-08-17T05:00:27.536010Z","iopub.status.idle":"2025-08-17T05:01:06.843344Z","shell.execute_reply.started":"2025-08-17T05:00:27.535978Z","shell.execute_reply":"2025-08-17T05:01:06.842515Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Device Settings","metadata":{}},{"cell_type":"code","source":"DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\nDATA_DIR = \"/kaggle/input/monkeypox-skin-lesion-dataset/Augmented Images/Augmented Images\"\nSAVE_DIR = \"/kaggle/working\"\nos.makedirs(SAVE_DIR, exist_ok=True)\n\nprint(f\"Device: {DEVICE}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-17T05:01:06.845279Z","iopub.execute_input":"2025-08-17T05:01:06.846053Z","iopub.status.idle":"2025-08-17T05:01:06.910828Z","shell.execute_reply.started":"2025-08-17T05:01:06.846030Z","shell.execute_reply":"2025-08-17T05:01:06.910092Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# DATA SETTINGS","metadata":{}},{"cell_type":"code","source":"SEED = 42\nBATCH_SIZE_SSL = 128         # for SimCLR pairs\nBATCH_SIZE_SUP = 128         # for supervised (linear eval / test)\nEPOCHS_SSL = 2000             # SimCLR pretraining epochs\nEPOCHS_LINEAR = 2000           # linear eval epochs\nTEMPERATURE = 0.5           # NT-Xent temperature\nFEATURE_DIM = 2048          # ResNet-50 penultimate layer output\nPROJ_DIM = 128              # projection head output\nIMG_SIZE = 224\nLR_SSL = 3e-4\nLR_LINEAR = 3e-4\n\ntorch.manual_seed(SEED)\nnp.random.seed(SEED)\nrandom.seed(SEED)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-17T05:01:06.911928Z","iopub.execute_input":"2025-08-17T05:01:06.912272Z","iopub.status.idle":"2025-08-17T05:01:06.966405Z","shell.execute_reply.started":"2025-08-17T05:01:06.912243Z","shell.execute_reply":"2025-08-17T05:01:06.965420Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Utils","metadata":{}},{"cell_type":"code","source":"def set_seed(seed=SEED):\n    torch.manual_seed(seed)\n    np.random.seed(seed)\n    random.seed(seed)\n\ndef plot_curve(values, title, xlab=\"Epoch\", ylab=\"Value\"):\n    plt.figure()\n    plt.plot(range(1, len(values)+1), values)\n    plt.title(title)\n    plt.xlabel(xlab)\n    plt.ylabel(ylab)\n    plt.grid(True)\n    plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-17T05:01:06.967338Z","iopub.execute_input":"2025-08-17T05:01:06.967618Z","iopub.status.idle":"2025-08-17T05:01:06.974896Z","shell.execute_reply.started":"2025-08-17T05:01:06.967597Z","shell.execute_reply":"2025-08-17T05:01:06.974163Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# SimCLR Transformation","metadata":{}},{"cell_type":"code","source":"class SimCLRTransform:\n    \"\"\"\n    Returns two augmented views for each image.\n    \"\"\"\n    def __init__(self, size=224):\n        s = 1.0\n        color_jitter = T.ColorJitter(0.8*s, 0.8*s, 0.8*s, 0.2*s)\n        self.train_transform = T.Compose([\n            T.RandomResizedCrop(size=size, scale=(0.2, 1.0)),\n            T.RandomHorizontalFlip(p=0.5),\n            T.RandomApply([color_jitter], p=0.8),\n            T.RandomGrayscale(p=0.2),\n            T.GaussianBlur(kernel_size=3),\n            T.ToTensor(),\n            T.Normalize(mean=[0.485, 0.456, 0.406],\n                        std=[0.229, 0.224, 0.225]),\n        ])\n\n    def __call__(self, x):\n        return self.train_transform(x), self.train_transform(x)\n\n# For supervised loaders (linear eval / test)\nSUPERVISED_TRANSFORM = T.Compose([\n    T.Resize((IMG_SIZE, IMG_SIZE)),\n    T.ToTensor(),\n    T.Normalize(mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225]),\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-17T05:01:06.975708Z","iopub.execute_input":"2025-08-17T05:01:06.975984Z","iopub.status.idle":"2025-08-17T05:01:06.991205Z","shell.execute_reply.started":"2025-08-17T05:01:06.975959Z","shell.execute_reply":"2025-08-17T05:01:06.990437Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Contrastive Pair Dataset","metadata":{}},{"cell_type":"code","source":"class ContrastivePairDataset(Dataset):\n    def __init__(self, image_folder: ImageFolder, transform_pair):\n        self.imgs = image_folder.imgs\n        self.loader = image_folder.loader\n        self.transform_pair = transform_pair\n\n    def __len__(self):\n        return len(self.imgs)\n\n    def __getitem__(self, idx):\n        path, _ = self.imgs[idx]\n        img = self.loader(path)\n        if not isinstance(img, Image.Image):\n            img = Image.open(path).convert(\"RGB\")\n        v1, v2 = self.transform_pair(img)\n        return v1, v2\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-17T05:01:06.992078Z","iopub.execute_input":"2025-08-17T05:01:06.992367Z","iopub.status.idle":"2025-08-17T05:01:07.005615Z","shell.execute_reply.started":"2025-08-17T05:01:06.992346Z","shell.execute_reply":"2025-08-17T05:01:07.004723Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Data Load & Split (20-80)","metadata":{}},{"cell_type":"code","source":"full_dataset_supervised = ImageFolder(root=DATA_DIR, transform=SUPERVISED_TRANSFORM)\nCLASS_TO_IDX = full_dataset_supervised.class_to_idx\nIDX_TO_CLASS = {v:k for k,v in CLASS_TO_IDX.items()}\nNUM_CLASSES = len(CLASS_TO_IDX)\nprint(\"Classes:\", CLASS_TO_IDX)\n\nn_total = len(full_dataset_supervised)\nn_train_ssl = int(0.4 * n_total)\nn_test = n_total - n_train_ssl\nssl_train_sup, test_sup = random_split(full_dataset_supervised, [n_train_ssl, n_test], generator=torch.Generator().manual_seed(SEED))\n\n# SSL Contrastive dataset uses the same images but returns pairs\nssl_train_contrast = ContrastivePairDataset(\n    ImageFolder(root=DATA_DIR),  # raw loader\n    transform_pair=SimCLRTransform(size=IMG_SIZE)\n)\n\nssl_train_indices = ssl_train_sup.indices if hasattr(ssl_train_sup, 'indices') else list(range(n_train_ssl))\nssl_train_subset = Subset(ssl_train_contrast, ssl_train_indices)\n\nssl_train_loader = DataLoader(ssl_train_subset, batch_size=BATCH_SIZE_SSL, shuffle=True, num_workers=2, drop_last=True)\n\n# Supervised loaders for downstream / test\ntrain_sup_loader = DataLoader(Subset(full_dataset_supervised, ssl_train_indices),\n                              batch_size=BATCH_SIZE_SUP, shuffle=True, num_workers=2)\ntest_loader = DataLoader(test_sup, batch_size=BATCH_SIZE_SUP, shuffle=False, num_workers=2)\n\nprint(f\"Total: {n_total} | SSL Train: {len(ssl_train_subset)} | Test: {len(test_sup)}\")\n\n# For downstream we also want a val split from the SSL-train portion\nval_ratio = 0.2\nn_train_down = int((1 - val_ratio) * len(ssl_train_indices))\nn_val_down = len(ssl_train_indices) - n_train_down\ntrain_down_indices, val_down_indices = random_split(ssl_train_indices, [n_train_down, n_val_down],\n                                                    generator=torch.Generator().manual_seed(SEED))\ntrain_down_loader = DataLoader(Subset(full_dataset_supervised, train_down_indices),\n                               batch_size=BATCH_SIZE_SUP, shuffle=True, num_workers=2)\nval_down_loader = DataLoader(Subset(full_dataset_supervised, val_down_indices),\n                             batch_size=BATCH_SIZE_SUP, shuffle=False, num_workers=2)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-17T05:01:07.006405Z","iopub.execute_input":"2025-08-17T05:01:07.006679Z","iopub.status.idle":"2025-08-17T05:01:08.052783Z","shell.execute_reply.started":"2025-08-17T05:01:07.006660Z","shell.execute_reply":"2025-08-17T05:01:08.052009Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# SimCLR setup","metadata":{}},{"cell_type":"code","source":"class ProjectionHead(nn.Module):\n    def __init__(self, in_dim=FEATURE_DIM, proj_dim=PROJ_DIM, hidden_dim=2048):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Linear(in_dim, hidden_dim),\n            nn.ReLU(inplace=True),\n            nn.Linear(hidden_dim, proj_dim)\n        )\n\n    def forward(self, x):\n        return self.net(x)\n\nclass SimCLR(nn.Module):\n    def __init__(self, proj_dim=PROJ_DIM):\n        super().__init__()\n        backbone = models.resnet50(weights=None)  # self-supervised from scratch\n        backbone.fc = nn.Identity()               # take 2048-d features\n        self.encoder = backbone\n        self.projector = ProjectionHead(in_dim=FEATURE_DIM, proj_dim=proj_dim)\n\n    def forward(self, x):\n        h = self.encoder(x)            # [B, 2048]\n        z = self.projector(h)          # [B, proj_dim]\n        z = F.normalize(z, dim=1)\n        return h, z\n\n# NT-Xent (InfoNCE) loss\ndef nt_xent_loss(z_i, z_j, temperature=0.5):\n    \"\"\"\n    z_i, z_j: [B, D] normalized\n    Returns: scalar loss\n    \"\"\"\n    batch_size = z_i.size(0)\n    z = torch.cat([z_i, z_j], dim=0)  # [2B, D]\n    sim = torch.matmul(z, z.T)        # [2B, 2B], cosine since z normalized\n\n    # remove self-similarity\n    mask = torch.eye(2*batch_size, dtype=torch.bool, device=z.device)\n    sim = sim.masked_fill(mask, -9e15)\n\n    # positives: diagonal across halves\n    positives = torch.cat([torch.arange(batch_size, 2*batch_size),\n                           torch.arange(0, batch_size)]).to(z.device)\n    numerator = torch.exp(sim[torch.arange(2*batch_size), positives] / temperature)\n\n    denominator = torch.sum(torch.exp(sim / temperature), dim=1)\n    loss = -torch.log(numerator / denominator).mean()\n    return loss\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-17T05:01:08.055275Z","iopub.execute_input":"2025-08-17T05:01:08.055539Z","iopub.status.idle":"2025-08-17T05:01:08.064411Z","shell.execute_reply.started":"2025-08-17T05:01:08.055521Z","shell.execute_reply":"2025-08-17T05:01:08.063625Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"simclr = SimCLR(proj_dim=PROJ_DIM).to(DEVICE)\nopt_ssl = torch.optim.Adam(simclr.parameters(), lr=LR_SSL)\n\nssl_loss_history = []\n\nprint(\"Starting SimCLR pretraining...\")\nfor epoch in range(1, EPOCHS_SSL + 1):\n    simclr.train()\n    running = 0.0\n    for v1, v2 in tqdm(ssl_train_loader, desc=f\"SSL Epoch {epoch}/{EPOCHS_SSL}\"):\n        v1, v2 = v1.to(DEVICE), v2.to(DEVICE)\n        _, z1 = simclr(v1)\n        _, z2 = simclr(v2)\n        loss = nt_xent_loss(z1, z2, temperature=TEMPERATURE)\n        opt_ssl.zero_grad()\n        loss.backward()\n        opt_ssl.step()\n        running += loss.item() * v1.size(0)\n    epoch_loss = running / (len(ssl_train_loader.dataset))\n    ssl_loss_history.append(epoch_loss)\n    print(f\"SSL Epoch {epoch}: loss={epoch_loss:.4f}\")\n\n# Save encoder weights\ntorch.save(simclr.encoder.state_dict(), os.path.join(SAVE_DIR, \"simclr_resnet50_encoder.pth\"))\nprint(\"Saved SimCLR encoder to:\", os.path.join(SAVE_DIR, \"simclr_resnet50_encoder.pth\"))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-17T05:01:08.065372Z","iopub.execute_input":"2025-08-17T05:01:08.065648Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def extract_features(dataloader, encoder):\n    encoder.eval()\n    feats, labs = [], []\n    with torch.no_grad():\n        for imgs, labels in dataloader:\n            imgs = imgs.to(DEVICE)\n            h = encoder(imgs)  # [B, 2048]\n            feats.append(h.cpu().numpy())\n            labs.append(labels.numpy())\n    feats = np.concatenate(feats, axis=0)\n    labs = np.concatenate(labs, axis=0)\n    return feats, labs\n\ndef subset_for_vis(dataloader, max_samples=1000):\n    xs, ys = [], []\n    total = 0\n    for imgs, labels in dataloader:\n        if total >= max_samples:\n            break\n        take = min(imgs.size(0), max_samples - total)\n        xs.append(imgs[:take])\n        ys.append(labels[:take])\n        total += take\n    X = torch.cat(xs, dim=0)\n    y = torch.cat(ys, dim=0)\n    return DataLoader(list(zip(X, y)), batch_size=BATCH_SIZE_SUP, shuffle=False)\n\n# Build a small vis set from the train_down set\nvis_loader = subset_for_vis(train_down_loader, max_samples=1000)\n\n# Reload a plain ResNet50 encoder and load weights (ensures clean .eval() model)\nencoder_vis = models.resnet50(weights=None)\nencoder_vis.fc = nn.Identity()\nencoder_vis.load_state_dict(torch.load(os.path.join(SAVE_DIR, \"simclr_resnet50_encoder.pth\"), map_location=DEVICE))\nencoder_vis = encoder_vis.to(DEVICE)\nencoder_vis.eval()\n\nvis_features, vis_labels = extract_features(vis_loader, encoder_vis)\n\n# t-SNE (2D)\nprint(\"Computing t-SNE on train features...\")\ntsne = TSNE(n_components=2, init=\"pca\", learning_rate=\"auto\", perplexity=30, random_state=SEED)\ntsne_2d = tsne.fit_transform(vis_features)\nplt.figure(figsize=(6,5))\nfor c in np.unique(vis_labels):\n    idx = vis_labels == c\n    plt.scatter(tsne_2d[idx,0], tsne_2d[idx,1], s=8, label=IDX_TO_CLASS[c], alpha=0.7)\nplt.legend()\nplt.title(\"SimCLR Train Features (t-SNE)\")\nplt.grid(True)\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Computing UMAP on train features...\")\nreducer = umap.UMAP(n_components=2, random_state=SEED)\numap_2d = reducer.fit_transform(vis_features)\nplt.figure(figsize=(6,5))\nfor c in np.unique(vis_labels):\n    idx = vis_labels == c\n    plt.scatter(umap_2d[idx,0], umap_2d[idx,1], s=8, label=IDX_TO_CLASS[c], alpha=0.7)\nplt.legend()\nplt.title(\"SimCLR Train Features (UMAP)\")\nplt.grid(True)\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"****SSL Loss Curve****","metadata":{}},{"cell_type":"code","source":"plot_curve(ssl_loss_history, \"SimCLR Training Loss\", \"Epoch\", \"NT-Xent Loss\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"****Downstream Linear Evaluation****","metadata":{}},{"cell_type":"code","source":"# Freeze encoder, train linear classifier on train_down, validate on val_down\nencoder_linear = models.resnet50(weights=None)\nencoder_linear.fc = nn.Identity()\nencoder_linear.load_state_dict(torch.load(os.path.join(SAVE_DIR, \"simclr_resnet50_encoder.pth\"), map_location=DEVICE))\nencoder_linear = encoder_linear.to(DEVICE)\nfor p in encoder_linear.parameters():\n    p.requires_grad = False\nencoder_linear.eval()\n\nclassifier = nn.Linear(FEATURE_DIM, NUM_CLASSES).to(DEVICE)\nopt_lin = torch.optim.Adam(classifier.parameters(), lr=LR_LINEAR)\ncriterion_ce = nn.CrossEntropyLoss()\n\nlin_train_losses, lin_val_losses = [], []\nlin_train_accs, lin_val_accs = [], []\n\nprint(\"Starting linear evaluation...\")\nfor epoch in range(1, EPOCHS_LINEAR + 1):\n    # Train classifier\n    classifier.train()\n    running_loss, correct, total = 0.0, 0, 0\n    for imgs, labels in tqdm(train_down_loader, desc=f\"Linear Epoch {epoch}/{EPOCHS_LINEAR}\"):\n        imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n        with torch.no_grad():\n            feats = encoder_linear(imgs)\n        logits = classifier(feats)\n        loss = criterion_ce(logits, labels)\n        opt_lin.zero_grad()\n        loss.backward()\n        opt_lin.step()\n\n        running_loss += loss.item() * imgs.size(0)\n        preds = logits.argmax(1)\n        correct += (preds == labels).sum().item()\n        total += labels.size(0)\n    train_loss = running_loss / total\n    train_acc = correct / total\n    lin_train_losses.append(train_loss)\n    lin_train_accs.append(train_acc)\n\n    # Validate\n    classifier.eval()\n    running_loss, correct, total = 0.0, 0, 0\n    all_preds, all_labels = [], []\n    with torch.no_grad():\n        for imgs, labels in val_down_loader:\n            imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n            feats = encoder_linear(imgs)\n            logits = classifier(feats)\n            loss = criterion_ce(logits, labels)\n            running_loss += loss.item() * imgs.size(0)\n            preds = logits.argmax(1)\n            correct += (preds == labels).sum().item()\n            total += labels.size(0)\n            all_preds.append(preds.cpu().numpy())\n            all_labels.append(labels.cpu().numpy())\n\n    val_loss = running_loss / total\n    val_acc = correct / total\n    lin_val_losses.append(val_loss)\n    lin_val_accs.append(val_acc)\n    print(f\"Linear Epoch {epoch}: TrainLoss={train_loss:.4f} Acc={train_acc:.3f} | ValLoss={val_loss:.4f} Acc={val_acc:.3f}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"****Downstream classification report****","metadata":{}},{"cell_type":"code","source":"val_y = np.concatenate(all_labels)\nval_pred = np.concatenate(all_preds)\nprint(\"\\nDownstream Validation Classification Report:\")\nprint(classification_report(val_y, val_pred, target_names=[IDX_TO_CLASS[i] for i in range(NUM_CLASSES)]))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"****Downstream curves****","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(12,4))\nplt.subplot(1,2,1)\nplt.plot(lin_train_losses, label='Train Loss')\nplt.plot(lin_val_losses, label='Val Loss')\nplt.title('Linear Eval Loss')\nplt.xlabel('Epoch'); plt.ylabel('Loss'); plt.grid(True); plt.legend()\n\nplt.subplot(1,2,2)\nplt.plot(lin_train_accs, label='Train Acc')\nplt.plot(lin_val_accs, label='Val Acc')\nplt.title('Linear Eval Accuracy')\nplt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.grid(True); plt.legend()\nplt.tight_layout(); plt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"****Testing****","metadata":{}},{"cell_type":"code","source":"classifier.eval()\ntest_labels_all, test_probs_all = [], []\ntest_preds_all = []\n\nwith torch.no_grad():\n    for imgs, labels in test_loader:\n        imgs = imgs.to(DEVICE); labels = labels.to(DEVICE)\n        feats = encoder_linear(imgs)\n        logits = classifier(feats)\n        probs = F.softmax(logits, dim=1)\n        preds = logits.argmax(1)\n\n        test_labels_all.append(labels.cpu().numpy())\n        test_probs_all.append(probs.cpu().numpy())\n        test_preds_all.append(preds.cpu().numpy())\n\ntest_labels_all = np.concatenate(test_labels_all)\ntest_probs_all = np.concatenate(test_probs_all)\ntest_preds_all = np.concatenate(test_preds_all)\n\nprint(\"\\nTest Classification Report:\")\nprint(classification_report(test_labels_all, test_preds_all, target_names=[IDX_TO_CLASS[i] for i in range(NUM_CLASSES)]))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"****ROC curve****","metadata":{}},{"cell_type":"code","source":"fpr, tpr, _ = roc_curve(test_labels_all, test_probs_all[:,1])\nauc = roc_auc_score(test_labels_all, test_probs_all[:,1])\nplt.figure()\nplt.plot(fpr, tpr, label=f\"AUC={auc:.3f}\")\nplt.plot([0,1], [0,1], '--')\nplt.xlabel(\"False Positive Rate\"); plt.ylabel(\"True Positive Rate\")\nplt.title(\"ROC Curve (Test)\")\nplt.grid(True); plt.legend(); plt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# t-SNE on TEST features (visual check of separability)\nprint(\"Computing t-SNE on TEST features...\")\ntest_features, test_labels_for_vis = extract_features(test_loader, encoder_linear)\ntsne_test = TSNE(n_components=2, init=\"pca\", learning_rate=\"auto\", perplexity=30, random_state=SEED)\ntsne_test_2d = tsne_test.fit_transform(test_features)\nplt.figure(figsize=(6,5))\nfor c in np.unique(test_labels_for_vis):\n    idx = test_labels_for_vis == c\n    plt.scatter(tsne_test_2d[idx,0], tsne_test_2d[idx,1], s=12, label=IDX_TO_CLASS[c], alpha=0.75)\nplt.legend(); plt.title(\"Test Features (t-SNE)\"); plt.grid(True); plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}